import sys
from pathlib import Path

import torch
import torch.nn as nn
import numpy as np
from tqdm import tqdm
import json
from datetime import datetime
import matplotlib.pyplot as plt
from ultralytics import YOLO
import cv2

# Ajoute la racine du projet au chemin de recherche de Python
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.data.data_loaders import get_dataloaders
from src.data.preprocessing import calculate_class_weights, convert_coco_to_yolo_segmentation
from config import *
from metrics import SegmentationMetrics


class YOLOv11Trainer:
    """
    EntraÃ®neur YOLOv11 pour la segmentation d'instance selon les paramÃ¨tres du paper LADOS.
    Utilise weighted BCE loss et les mÃªmes mÃ©triques (IoU, mAcc) que SegFormer.
    """
    
    def __init__(self):
        self.device = torch.device(DEVICE)
        self.num_classes = NUM_CLASSES
        
        # 1. ModÃ¨le YOLOv11 (prÃ©-entraÃ®nÃ© sur COCO)
        self.model = self._initialize_model()
        
        # 2. Poids de classe pour weighted BCE loss
        weights_path = DATA_DIR / 'class_weights.pt'
        if weights_path.exists():
            self.class_weights = torch.load(weights_path)
        else:
            self.class_weights = calculate_class_weights()
            torch.save(self.class_weights, weights_path)
        
        # 3. MÃ©triques et Suivi
        self.train_metrics = SegmentationMetrics(NUM_CLASSES)
        self.val_metrics = SegmentationMetrics(NUM_CLASSES)
        self.best_miou = -1.0
        self.best_map = -1.0  # Pour mAP@50-95 (utilisÃ© pour early stopping)
        self.patience_counter = 0
        self.history = {
            'train_loss': [], 
            'val_loss': [], 
            'train_miou': [], 
            'val_miou': [],
            'val_map50': [],
            'val_map50_95': []
        }
        
        # 4. Directories
        self.checkpoint_dir = OUTPUT_DIR_YOLO / 'checkpoints'
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"YOLOv11 Trainer initialisÃ© sur {self.device}.")
        print(f"Poids de classe: {self.class_weights}")

    def _initialize_model(self):
        """Initialise YOLOv11m-seg avec poids COCO."""
        model = YOLO('yolo11m-seg.pt')  # YOLOv11m segmentation
        return model
    
    def _prepare_yolo_format(self):
        """
        PrÃ©pare les donnÃ©es au format YOLO (conversion des masques en polygones).
        Utilise le module yolo_data_converter.
        """
        
        yolo_data_dir = DATA_DIR / 'yolo_format'
        yaml_path = yolo_data_dir / 'data.yaml'
        
        # VÃ©rifier si la conversion est dÃ©jÃ  faite
        if yaml_path.exists():
            print(f"âœ… DonnÃ©es YOLO dÃ©jÃ  converties: {yolo_data_dir}")
            return str(yaml_path)
        
        # Sinon, lancer la conversion
        print("ðŸ”„ Conversion COCO â†’ YOLO en cours...")
        convert_coco_to_yolo_segmentation(DATA_DIR, yolo_data_dir)
        
        return str(yaml_path)
    
    def train(self):
        """
        EntraÃ®nement YOLOv11 avec les paramÃ¨tres du paper LADOS:
        - Batch size: 32
        - Epochs: max 80 (avec early stopping patience=10)
        - Optimizer: AdamW implicite dans YOLO
        - Augmentations: mosaic, HSV, flip, translate, scale
        - Early stopping basÃ© sur weighted average mAP (0.1*mAP@50 + 0.9*mAP@50-95)
        """
        print("\nðŸš€ DÃ©but de l'entraÃ®nement YOLOv11...")
        start_time = datetime.now()
        
        # PrÃ©parer le format YOLO
        data_yaml_path = self._prepare_yolo_format()
        
        # Configuration d'entraÃ®nement selon le paper
        results = self.model.train(
            data=data_yaml_path,
            epochs=NUM_EPOCHS_YOLO,  # Max epochs (early stopping activÃ©)
            batch=BATCH_SIZE_YOLO,  # 32 selon paper
            imgsz=TARGET_SIZE[0],
            device=self.device,
            
            # Optimizer (AdamW implicite)
            optimizer='AdamW',
            lr0=LEARNING_RATE_YOLO,
            weight_decay=WEIGHT_DECAY,
            
            # Early stopping (patience=10 selon paper)
            patience=PATIENCE,
            
            # Augmentations (selon paper section 4.3)
            mosaic=1.0,  # Mosaic augmentation
            hsv_h=0.015,  # HSV-Hue augmentation
            hsv_s=0.7,    # HSV-Saturation
            hsv_v=0.4,    # HSV-Value
            degrees=0.0,  # Rotation (pas mentionnÃ© dans paper)
            translate=0.1,  # Translation
            scale=0.5,    # Scaling
            fliplr=0.5,   # Horizontal flip
            
            # Loss weights (BCE pour masks)
            box=7.5,
            cls=0.5,
            dfl=1.5,
            
            # Sauvegarde
            project=str(OUTPUT_DIR_YOLO),
            name='yolo_training',
            exist_ok=True,
            save=True,
            save_period=5,
            
            # Validation
            val=True,
            plots=True,
            verbose=True
        )
        
        training_time = (datetime.now() - start_time).total_seconds() / 3600
        print(f"\n--- ENTRAÃŽNEMENT TERMINÃ‰ ---")
        print(f"Temps total : {training_time:.2f} heures.")
        
        # Ã‰valuation finale sur test set
        self._evaluate_with_metrics()
        
        return results
    
    def _evaluate_with_metrics(self):
        """
        Ã‰value le modÃ¨le sur le test set avec les mÃ©triques du paper:
        - IoU par classe
        - mIoU (excluant background)
        - mAcc
        
        Note: YOLO prÃ©dit des masques d'instance, nous devons les convertir en 
        masques sÃ©mantiques en assignant chaque pixel Ã  la classe avec le plus 
        haut score de confiance (comme mentionnÃ© dans le paper section 4.4).
        """
        print("\n" + "="*50)
        print("ðŸ“Š Ã‰VALUATION FINALE SUR TEST SET")
        print("="*50)
        
        # Charger le meilleur modÃ¨le
        best_model_path = OUTPUT_DIR_YOLO / 'yolo_training' / 'weights' / 'best.pt'
        if not best_model_path.exists():
            print("âš ï¸ Meilleur modÃ¨le non trouvÃ©, utilisation du modÃ¨le actuel.")
            model = self.model
        else:
            model = YOLO(str(best_model_path))
        
        # RÃ©cupÃ©rer le test loader
        loaders = get_dataloaders()
        test_loader = loaders['test']
        
        # MÃ©triques
        test_metrics = SegmentationMetrics(NUM_CLASSES)
        
        model.model.eval()
        print("\nðŸ” PrÃ©diction sur le test set...")
        
        with torch.no_grad():
            for batch in tqdm(test_loader, desc="Testing"):
                images, masks = batch
                
                # Conversion pour YOLO (numpy format)
                for i in range(images.shape[0]):
                    img = images[i].cpu().numpy().transpose(1, 2, 0)
                    img = (img * 255).astype(np.uint8)
                    gt_mask = masks[i].cpu().numpy()
                    
                    # PrÃ©diction YOLO
                    results = model.predict(img, verbose=False, device=self.device)
                    
                    # Conversion instance -> semantic mask
                    # (selon paper section 4.4: pixel assignÃ© Ã  la classe avec highest confidence)
                    pred_mask = self._convert_instance_to_semantic(
                        results[0], 
                        img.shape[:2]
                    )
                    
                    # Mise Ã  jour des mÃ©triques
                    test_metrics.update(pred_mask, gt_mask)
        
        # Calcul des rÃ©sultats finaux
        results = test_metrics.get_results()
        
        print(f"\nâœ… RÃ©sultats finaux (mIoU): {results['mIoU']:.4f}")
        print(f"   mAcc: {results['mAcc']:.4f}")
        print("\nðŸ“‹ IoU par classe:")
        for class_id, iou in enumerate(results['class_iou']):
            class_name = CLASS_NAMES.get(class_id, f"Class_{class_id}")
            print(f"  {class_name:15s}: {iou:.4f}")
        
        # Sauvegarder les rÃ©sultats
        results_path = OUTPUT_DIR_YOLO / 'test_results.json'
        with open(results_path, 'w') as f:
            json.dump({
                'mIoU': float(results['mIoU']),
                'mAcc': float(results['mAcc']),
                'class_iou': [float(x) for x in results['class_iou']],
                'class_names': [CLASS_NAMES[i] for i in range(NUM_CLASSES)]
            }, f, indent=2)
        
        print(f"\nðŸ’¾ RÃ©sultats sauvegardÃ©s dans: {results_path}")
    
    def _convert_instance_to_semantic(self, result, img_shape):
        """
        Convertit les masques d'instance YOLO en masque sÃ©mantique.
        
        Selon le paper (section 4.4):
        "we assigned each predicted pixel the class with the highest confidence score"
        
        Args:
            result: RÃ©sultat YOLO (contient masks, boxes, cls, conf)
            img_shape: (H, W) de l'image
            
        Returns:
            semantic_mask: np.ndarray de shape (H, W) avec les class IDs
        """
        H, W = img_shape
        semantic_mask = np.zeros((H, W), dtype=np.int64)
        confidence_map = np.zeros((H, W), dtype=np.float32)
        
        if result.masks is None:
            return semantic_mask
        
        # RÃ©cupÃ©rer les masques, classes et confidences
        masks = result.masks.data.cpu().numpy()  # (N, H, W)
        classes = result.boxes.cls.cpu().numpy().astype(int)  # (N,)
        confidences = result.boxes.conf.cpu().numpy()  # (N,)
        
        # Redimensionner les masques Ã  la taille de l'image
        for mask, cls, conf in zip(masks, classes, confidences):
            # Resize mask
            mask_resized = cv2.resize(mask, (W, H), interpolation=cv2.INTER_LINEAR)
            mask_binary = mask_resized > 0.5
            
            # Pour chaque pixel du masque, garder la classe avec la plus haute confiance
            update_mask = (mask_binary) & (conf > confidence_map)
            semantic_mask[update_mask] = cls
            confidence_map[update_mask] = conf
        
        return semantic_mask

if __name__ == '__main__':
    trainer = YOLOv11Trainer()
    trainer.train()