"""
Fusion de YOLOv11 et SegFormer pour la d√©tection d'oil spills.

Strat√©gies impl√©ment√©es:
1. Weighted Average (simple)
2. Class-Specific Fusion (liquides vs solides)
3. Confidence-Based Selection
4. Ensemble Voting

Bas√© sur le paper LADOS et le State of the Art.
"""

import sys
from pathlib import Path
import torch
import torch.nn.functional as F
import numpy as np
from tqdm import tqdm
import json
from datetime import datetime
import matplotlib.pyplot as plt
import cv2
from ultralytics import YOLO
import os
from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.data.data_loaders import get_dataloaders
from config import *
from metrics import SegmentationMetrics


class ModelFusion:
    """
    Classe pour fusionner les pr√©dictions de YOLOv11 et SegFormer.
    
    Strat√©gies de fusion:
    - weighted_average: Moyenne pond√©r√©e des probabilit√©s
    - class_specific: SegFormer pour liquides, YOLO pour solides
    - confidence_based: S√©lection bas√©e sur la confiance
    - voting: Vote majoritaire par pixel
    """
    
    def __init__(
        self,
        yolo_model_path: str,
        segformer_model_path: str,
        device: str = DEVICE
    ):
        """
        Initialise les deux mod√®les.
        
        Args:
            yolo_model_path: Chemin vers best.pt de YOLO
            segformer_model_path: Chemin vers best_model.pt de SegFormer
            device: 'cuda' ou 'cpu'
        """
        self.device = torch.device(device)
        
        # 1. Chargement de YOLOv11
        print(f"üîÑ Chargement de YOLOv11 depuis {yolo_model_path}...")
        self.yolo_model = YOLO(yolo_model_path)
        
        # 2. Chargement de SegFormer
        print(f"üîÑ Chargement de SegFormer depuis {segformer_model_path}...")
        self.seg_model = SegformerForSemanticSegmentation.from_pretrained(
            MODEL_NAME_SEG, 
            num_labels=NUM_CLASSES,
            ignore_mismatched_sizes=True
        ).to(self.device)
        
        # Chargement des poids entra√Æn√©s (gestion de l'√©tat du dictionnaire)
        checkpoint = torch.load(segformer_model_path, map_location=self.device, weights_only=False)
        state_dict = checkpoint['model_state_dict']
        # Nettoyage si le mod√®le a √©t√© sauvegard√© avec 'torch.compile'
        state_dict = {k.replace('_orig_mod.', ''): v for k, v in state_dict.items()}
        self.seg_model.load_state_dict(state_dict)
        self.seg_model.eval()
        
        # Processor pour SegFormer
        self.processor = SegformerImageProcessor.from_pretrained(MODEL_NAME_SEG)
        
        # Param√®tres de d√©normalisation
        self.mean = np.array([0.485, 0.456, 0.406])
        self.std = np.array([0.229, 0.224, 0.225])
        
        # Classes liquides vs solides (selon analyse de compl√©mentarit√©)
        self.liquid_classes = [1, 2, 3]  # Oil, Emulsion, Sheen
        self.solid_classes = [4, 5]      # Ship, Oil-platform
        
        print("‚úÖ Mod√®les charg√©s avec succ√®s!")
    
    def predict_yolo(self, image: np.ndarray, conf: float = 0.3, iou: float = 0.45):
        """
        Pr√©diction YOLO (instance ‚Üí semantic).
        
        Args:
            image: Image RGB uint8 (H, W, 3)
            conf: Seuil de confiance
            iou: Seuil NMS
            
        Returns:
            mask: Masque s√©mantique (H, W) avec classes 0-5
            probs: Probabilit√©s par classe (H, W, 6)
        """
        H, W = image.shape[:2]

        if image.max() <= 1.0:
            image = (image * 255).astype(np.uint8)
        
        # Pr√©diction YOLO
        results = self.yolo_model.predict(
            image,
            verbose=False,
            device=self.device,
            imgsz=TARGET_SIZE[0],
            conf=conf,
            iou=iou
        )[0]
        
        # Initialiser masque et probabilit√©s
        mask = np.zeros((H, W), dtype=np.int64)
        probs = np.zeros((H, W, NUM_CLASSES), dtype=np.float32)
        probs[:, :, 0] = 1.0  # Background par d√©faut
        confidence_map = np.zeros((H, W), dtype=np.float32)
        
        if results.masks is None:
            return mask, probs
        
        # Convertir instances ‚Üí semantic
        masks_data = results.masks.data.cpu().numpy()
        classes = results.boxes.cls.cpu().numpy().astype(int)
        confidences = results.boxes.conf.cpu().numpy()
        
        for inst_mask, yolo_cls, conf in zip(masks_data, classes, confidences):
            # Resize et binariser
            inst_mask_resized = cv2.resize(inst_mask, (W, H), interpolation=cv2.INTER_LINEAR)
            binary_mask = inst_mask_resized > 0.5
            
            # Mapping YOLO (0-4) ‚Üí GT (1-5)
            gt_cls = yolo_cls + 1
            
            # Mettre √† jour l√† o√π la confiance est plus haute
            update_pixels = binary_mask & (conf > confidence_map)
            mask[update_pixels] = gt_cls
            
            # Probabilit√©s: mettre 0 sur background, conf sur la classe
            probs[update_pixels, 0] = 0.0
            probs[update_pixels, gt_cls] = conf
            confidence_map[update_pixels] = conf
        
        # Renormaliser les probabilit√©s
        probs_sum = probs.sum(axis=2, keepdims=True)
        probs_sum[probs_sum == 0] = 1.0  # √âviter division par 0
        probs = probs / probs_sum
        
        return mask, probs
    
    def predict_segformer(self, image_tensor: torch.Tensor):
        """
        Pr√©diction SegFormer.
        
        Args:
            image_tensor: Tensor normalis√© (3, H, W)
            
        Returns:
            mask: Masque s√©mantique (H, W) avec classes 0-5
            probs: Probabilit√©s par classe (H, W, 6)
        """
        with torch.no_grad():
            # Forward pass
            outputs = self.seg_model(pixel_values=image_tensor.unsqueeze(0).to(self.device))
            logits = outputs.logits
            
            # Upsample vers taille originale
            logits_upsampled = F.interpolate(
                logits,
                size=image_tensor.shape[-2:],
                mode='bilinear',
                align_corners=False
            )
            
            # Softmax pour probabilit√©s
            probs_tensor = F.softmax(logits_upsampled, dim=1)  # (1, 6, H, W)
            probs = probs_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()  # (H, W, 6)
            
            # Masque argmax
            mask = probs_tensor.argmax(dim=1).squeeze(0).cpu().numpy()  # (H, W)
        
        return mask, probs
    
    # ========================================================================
    # STRAT√âGIES DE FUSION
    # ========================================================================
    
    
    def fuse_adaptive(self, yolo_probs, seg_probs):
        """
        Fusion adaptative avec poids optimis√©s par classe:
        - Liquides (Oil, Emulsion, Sheen) : SegFormer dominant (stabilit√© des textures)
        - Ship : YOLO ultra-dominant (contours nets)
        - Background & Oil-platform : √âquilibre (0.4/0.6)
        """
        H, W, C = yolo_probs.shape
        fused_probs = np.zeros((H, W, C))
        
        # Poids optimis√©s (w_yolo, w_seg) par classe
        class_weights = {
            0: (0.40, 0.60),  # Background
            1: (0.15, 0.85),  # Oil
            2: (0.05, 0.95),  # Emulsion
            3: (0.10, 0.90),  # Sheen
            4: (0.85, 0.15),  # Ship
            5: (0.40, 0.60),  # Oil-platform
        }
        
        for cls in range(C):
            w_yolo, w_seg = class_weights.get(cls, (0.4, 0.6))
            fused_probs[:, :, cls] = (w_yolo * yolo_probs[:, :, cls]) + (w_seg * seg_probs[:, :, cls])
        
        return fused_probs.argmax(axis=2)




                
    # ========================================================================
    # √âVALUATION
    # ========================================================================
    
    def evaluate_all_strategies(self, test_loader=None, save_results: bool = True, num_samples: int = 350):
        """
        √âvalue les strat√©gies de fusion sur le test set.
        
        Args:
            test_loader: DataLoader test (si None, charge depuis get_dataloaders)
            save_results: Sauvegarder les r√©sultats dans JSON
            num_samples: Nombre d'images √† √©valuer
            
        Returns:
            results: Dict avec les r√©sultats de chaque strat√©gie
        """
        if test_loader is None:
            test_loader = get_dataloaders()['test']
        
        print("\n" + "‚ñì" * 80)
        print("‚ñà" + " " * 78 + "‚ñà")
        print("‚ñà" + " " * 25 + "üî¨ √âVALUATION DES MOD√àLES DE FUSION" + " " * 18 + "‚ñà")
        print("‚ñà" + " " * 78 + "‚ñà")
        print("‚ñì" * 80)
        
        # M√©triques pour chaque strat√©gie
        strategies = {
            'yolo_only': SegmentationMetrics(NUM_CLASSES),
            'segformer_only': SegmentationMetrics(NUM_CLASSES),
            'fusion_adaptive': SegmentationMetrics(NUM_CLASSES),
        }
        
        for metric in strategies.values():
            metric.reset()
        
        print(f"\n   üìä √âvaluation sur {num_samples} images du test set...\n")
        count = 0
        with torch.no_grad():
            for batch_idx, (images, masks) in enumerate(tqdm(test_loader, desc="   ‚è≥ Traitement", ncols=70)):
                if count >= num_samples: 
                    break
                for i in range(images.shape[0]):
                    if count >= num_samples:
                        break
                    # Ground truth
                    gt_mask = masks[i].cpu().numpy()
                    
                    # Image pour YOLO (d√©normalis√©e)
                    img_np = images[i].permute(1, 2, 0).cpu().numpy()
                    img_denorm = img_np * self.std + self.mean
                    img_uint8 = (img_denorm * 255).clip(0, 255).astype(np.uint8)
                    
                    # Image pour SegFormer (normalis√©e)
                    img_tensor = images[i]
                    
                    # === PR√âDICTIONS ===
                    yolo_mask, yolo_probs = self.predict_yolo(img_uint8)
                    seg_mask, seg_probs = self.predict_segformer(img_tensor)
                    
                    # === FUSION ===
                    fused_masks = {
                        'yolo_only': yolo_mask,
                        'segformer_only': seg_mask,
                        'fusion_adaptive': self.fuse_adaptive(yolo_probs, seg_probs),
                    }
                    
                    # Mise √† jour des m√©triques
                    for strategy_name, fused_mask in fused_masks.items():
                        strategies[strategy_name].update(fused_mask, gt_mask)
                    count += 1
        
        # === R√âSULTATS ===
        print("\n" + "‚ñì" * 80)
        print("‚ñà" + " " * 78 + "‚ñà")
        print("‚ñà" + " " * 30 + "üìä R√âSULTATS FINAUX" + " " * 29 + "‚ñà")
        print("‚ñà" + " " * 78 + "‚ñà")
        print("‚ñì" * 80)
        
        results = {}
        strategy_order = ['yolo_only', 'segformer_only', 'fusion_adaptive']
        
        for strategy_name in strategy_order:
            metric = strategies[strategy_name]
            res = metric.get_results()
            results[strategy_name] = {
                'mIoU': float(res['mIoU']),
                'mAcc': float(res['mAcc']),
                'class_iou': [float(x) for x in res['class_iou']],
                'timestamp': datetime.now().isoformat()
            }
            
            # Affichage joli
            strategy_display = {
                'yolo_only': 'üü° YOLO Seul',
                'segformer_only': 'üü¢ SegFormer Seul',
                'fusion_adaptive': 'üîµ Fusion Adaptative',
            }
            
            print(f"\n   {strategy_display.get(strategy_name, strategy_name)}")
            print(f"   {'‚îÄ' * 60}")
            print(f"   ‚îÇ  üìà mIoU (Intersection over Union):  {res['mIoU']*100:6.2f}%")
            print(f"   ‚îÇ  üéØ mAcc (Moyenne Accuracy):        {res['mAcc']*100:6.2f}%")
            print(f"   ‚îÇ")
            print(f"   ‚îÇ  IoU par classe:")
            
            class_names = ['Background', 'Oil', 'Emulsion', 'Sheen', 'Ship', 'Oil-Platform']
            for cls_id, iou in enumerate(res['class_iou']):
                icon = '‚¨õ' if cls_id == 0 else '‚ñ™Ô∏è'
                print(f"   ‚îÇ    {icon} {class_names[cls_id]:15s} : {iou*100:6.2f}%")
            
            print(f"   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        
        OUTPUT_DIR_FUSION = project_root / "output" / "fusion"
        
        # Sauvegarder
        if save_results:
            results_path = OUTPUT_DIR_FUSION / 'fusion_results.json'
            results_path.parent.mkdir(parents=True, exist_ok=True)
            with open(results_path, 'w') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            print(f"\n   ‚úÖ R√©sultats sauvegard√©s: {results_path}")
        
        return results
    
    def visualize_comparison(
        self,
        image_tensor: torch.Tensor,
        gt_mask: np.ndarray,
        save_path: str = None
    ):
        """
        Visualise les pr√©dictions de chaque strat√©gie sur une image.
        
        Args:
            image_tensor: Image normalis√©e (3, H, W)
            gt_mask: Ground truth (H, W)
            save_path: Chemin de sauvegarde (optionnel)
        """
        # D√©normaliser pour affichage
        img_np = image_tensor.permute(1, 2, 0).cpu().numpy()
        img_denorm = img_np * self.std + self.mean
        img_uint8 = (img_denorm * 255).clip(0, 255).astype(np.uint8)
        
        # Pr√©dictions
        yolo_mask, yolo_probs = self.predict_yolo(img_uint8)
        seg_mask, seg_probs = self.predict_segformer(image_tensor)
        
        # Fusion
        adaptive = self.fuse_adaptive(yolo_probs, seg_probs)
        
        # Plot
        fig, axes = plt.subplots(1, 5, figsize=(25, 5))
        
        titles = [
            'Image Originale', 'Ground Truth', 'YOLO Seul', 'SegFormer Seul', 'Fusion Adaptative'
        ]
        
        masks_to_plot = [
            img_uint8, gt_mask, yolo_mask, seg_mask, adaptive
        ]
        
        cmap = plt.cm.get_cmap('tab20')
        
        for ax, title, mask_data in zip(axes.flat, titles, masks_to_plot):
            if title == 'Image Originale':
                ax.imshow(mask_data)
            else:
                im = ax.imshow(mask_data, cmap='tab10', vmin=0, vmax=5)
            ax.set_title(title, fontsize=13, fontweight='bold', pad=10)
            ax.axis('off')
        
        plt.tight_layout()
        
        if save_path:
            Path(save_path).parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"\n   ‚úÖ Visualisation sauvegard√©e: {save_path}")
        
        plt.show()


# ============================================================================
# FONCTIONS UTILITAIRES
# ============================================================================

def create_fusion_comparison_table(results: dict) -> str:
    """
    Cr√©e un tableau comparatif format Markdown.
    
    Args:
        results: R√©sultats de evaluate_all_strategies()
        
    Returns:
        table: Tableau Markdown
    """
    lines = []
    lines.append("| Strat√©gie | mIoU | mAcc | Oil | Emulsion | Sheen | Ship | Oil-plat. |")
    lines.append("|-----------|------|------|-----|----------|-------|------|-----------|")
    
    for strategy, res in results.items():
        miou = res['mIoU'] * 100
        macc = res['mAcc'] * 100
        ious = [iou * 100 for iou in res['class_iou'][1:]]  # Skip background
        
        line = f"| {strategy:20s} | {miou:5.2f} | {macc:5.2f} |"
        for iou in ious:
            line += f" {iou:5.2f} |"
        lines.append(line)
    
    return "\n".join(lines)


# ============================================================================
# SCRIPT PRINCIPAL
# ============================================================================

if __name__ == '__main__':
    print("\n" + "‚ïî" + "‚ïê" * 78 + "‚ïó")
    print("‚ïë" + " " * 20 + "üöÄ FUSION YOLOV11 + SEGFORMER - OIL SPILL DETECTION" + " " * 6 + "‚ïë")
    print("‚ïö" + "‚ïê" * 78 + "‚ïù")

    YOLO_PATH = project_root / "output" / "yolo_best.pt"
    SEG_PATH = project_root / "output" / "segformer_best.pt"
    OUTPUT_DIR_FUSION = project_root / "output" / "fusion"
        
    
    # V√©rifier existence
    if not YOLO_PATH.exists():
        print(f"\n   ‚ùå YOLO non trouv√©: {YOLO_PATH}")
        sys.exit(1)
    if not SEG_PATH.exists():
        print(f"\n   ‚ùå SegFormer non trouv√©: {SEG_PATH}")
        sys.exit(1)
    
    print(f"\n   ‚úÖ Mod√®les trouv√©s:")
    print(f"      ‚Ä¢ YOLO:      {YOLO_PATH}")
    print(f"      ‚Ä¢ SegFormer: {SEG_PATH}")
    
    # Cr√©er la fusion
    print(f"\n   ‚è≥ Initialisation des mod√®les...")
    fusion = ModelFusion(
        yolo_model_path=str(YOLO_PATH),
        segformer_model_path=str(SEG_PATH)
    )
    
    # √âvaluer toutes les strat√©gies
    print("\n")
    results = fusion.evaluate_all_strategies(num_samples=350)
    
    # Tableau comparatif
    print("\n" + "‚ïî" + "‚ïê" * 78 + "‚ïó")
    print("‚ïë" + " " * 32 + "üìã TABLEAU R√âCAPITULATIF" + " " * 22 + "‚ïë")
    print("‚ïö" + "‚ïê" * 78 + "‚ïù")
    print(create_fusion_comparison_table(results))
    
    # Visualisation d'exemple
    print("\n   üìä Test sur une image du dataset...")
    test_loader = get_dataloaders()['test']
    images, masks = next(iter(test_loader))
    
    fusion.visualize_comparison(
        images[0],
        masks[0].cpu().numpy(),
        save_path=str(OUTPUT_DIR_FUSION / 'fusion_comparison_example.png')
    )
    
    print("\n" + "‚ïî" + "‚ïê" * 78 + "‚ïó")
    print("‚ïë" + " " * 25 + "‚úÖ FUSION TERMIN√âE AVEC SUCC√àS!" + " " * 21 + "‚ïë")
    print("‚ïö" + "‚ïê" * 78 + "‚ïù\n")